#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

ARG base_img

FROM ${base_img:-spark}
LABEL org.opencontainers.image.authors="Apache Spark project <dev@spark.apache.org>"
LABEL org.opencontainers.image.licenses="Apache-2.0"
LABEL org.opencontainers.image.ref.name="Apache Spark Python Image"
# Overwrite this label to avoid exposing the underlying Ubuntu OS version label
LABEL org.opencontainers.image.version=""
WORKDIR /

# Reset to root to run installation tasks
USER 0

RUN mkdir ${SPARK_HOME}/python
COPY python/pyspark ${SPARK_HOME}/python/pyspark
COPY python/lib ${SPARK_HOME}/python/lib


RUN apt-get update && apt-get install -y curl ca-certificates && \
    # Install uv
    curl -LsSf https://astral.sh/uv/install.sh | sh && \
    # Make uv available globally
    mv /root/.local/bin/uv /usr/local/bin/uv && \
    # Create Python installation directory
    mkdir -p /opt/python && \
    # Install Python 3.12.9 using uv to specific directory
    UV_PYTHON_INSTALL_DIR=/opt/python uv python install 3.10.12 && \
    # Create symlinks for global access
    ln -sf /opt/python/cpython-3.10.12-linux-x86_64-gnu/bin/python3 /usr/local/bin/python && \
    ln -sf /opt/python/cpython-3.10.12-linux-x86_64-gnu/bin/python3 /usr/local/bin/python3 && \
    ln -sf /opt/python/cpython-3.10.12-linux-x86_64-gnu/bin/pip3 /usr/local/bin/pip && \
    ln -sf /opt/python/cpython-3.10.12-linux-x86_64-gnu/bin/pip3 /usr/local/bin/pip3 && \
    # Set proper permissions
    chmod -R 755 /opt/python && \
    # Clean up
    rm -rf /var/lib/apt/lists/*

# Set environment variables for Python
ENV UV_PYTHON_INSTALL_DIR="/opt/python"
ENV PATH="/opt/python/cpython-3.10.12-linux-x86_64-gnu/bin:$PATH"
ENV PYTHONPATH="${SPARK_HOME}/python:${PYTHONPATH}"

# Verify installation
RUN python --version && pip --version && which python

WORKDIR /opt/spark/work-dir
ENTRYPOINT [ "/opt/entrypoint.sh" ]

# Specify the User that the actual main process will run as
ARG spark_uid=185
COPY spark_kafka_test.py /opt/python/spark_kafka_test.py
##below two lines to make ivy cache work
RUN chown -R 185 /opt/spark
USER ${spark_uid}