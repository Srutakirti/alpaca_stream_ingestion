kafka:
  # bootstrap_servers: "instance-20250325-162745:9095"
  # bootstrap_servers: "localhost:9092"
  bootstrap_servers: "my-cluster-kafka-bootstrap.kafka.svc.cluster.local:9092"
  bootstrap_servers_local: "192.168.49.2:32100"
  topics:
    raw_trade: "iex-topic-1"
    flattened_trade: "iex-topic-1-flattened"
  consumer:
    group_id: "offset-checker"
    enable_auto_commit: false

alpaca:
  key: ""  # Set via environment variable ALPACA_KEY
  secret: ""  # Set via environment variable ALPACA_SECRET
  websocket_uri: "wss://stream.data.alpaca.markets/v2/iex"
  symbols: ["*"]
  timeout: 120
  max_retries: 5
  backoff_max: 120

spark:
  warehouse_path: "gs://alpaca-streamer/warehouse_poc"
  jars:
    - "org.apache.spark:spark-sql-kafka-0-10_2.13:3.5.1"
    - "org.apache.iceberg:iceberg-spark-runtime-3.5_2.13:1.8.1"
  processing_time: "60 seconds"
  iceberg:
    catalog: "spark_catalog"
    catalog_type: "hadoop"
  app_name: KafkaToIcebergAndBQStreamer
  spark_catalog: org.apache.iceberg.spark.SparkCatalog
  spark_catalog_type: hadoop

gcp:
  project_id: "coe-landing-zone-18-ats-2246"
  region: "us-east1"
  cluster_name: "alpaca-streamer"
  storage:
    bucket: "alpaca-streamer"
    checkpoints_prefix: "checkpoints/a"
    warehouse_prefix: "warehouse_poc"
  bigquery:
    table: "coe-landing-zone-18-ats-2246.alpaca_data.raw_alpaca_spark_stream"

logging:
  level: "INFO"
  name: "websocket-kafka-logger"
  mode: "stdout"

pinot:
  #controller_url is not needed if dynamically detected which is happeining now in the setup python script
  controller_url: "http://192.168.49.2:30900"  # NodePort for external access (no port-forward needed)
  schema_file: "load/schema.json"
  table_file: "load/table.json"

# MinIO configuration
minio:
  minikube_ip: "192.168.49.2"  # Update this for your Minikube instance
  rootUser: "minio"
  rootPassword: "minio123"
  storage:
    size: 100Gi
    path: /mnt/minio  # Local mount path on Minikube node
  browser: "on"